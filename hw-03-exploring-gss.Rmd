---
title: "HW 03 - Exploring the GSS"
author: "Moriah Ruggerio"
output:
  pdf_document:
    latex_engine: xelatex
  html_document: default
---

```{r include = FALSE}
knitr::opts_chunk$set(
  eval = TRUE,
  out.width = "80%",
  fig.asp = 0.618,
  fig.width = 10,
  dpi = 300
)
```

```{r photo,  echo = FALSE, fig.width = 3, fig.cap = "Photo by Mauro Mora on Unsplash", eval = TRUE}
knitr::include_graphics("img/mauro-mora-31-pOduwZGE-unsplash.jpg")
```

The GSS gathers data on contemporary American society in order to monitor and explain trends and constants in attitudes, behaviours, and attributes.
Hundreds of trends have been tracked since 1972.
In addition, since the GSS adopted questions from earlier surveys, trends can be followed for up to 70 years.

The GSS contains a standard core of demographic, behavioural, and attitudinal questions, plus topics of special interest.
Among the topics covered are civil liberties, crime and violence, intergroup tolerance, morality, national spending priorities, psychological well-being, social mobility, and stress and traumatic events.

In this assignment we analyze data from the 2016 GSS, using it to estimate values of population parameters of interest about US adults.[^hw-08-exploring-gss-1]


## Warm up

Before we introduce the data, let's warm up with some simple exercises.
Update the YAML of your R Markdown file with your information, knit, commit, and push your changes.
Make sure to commit with a meaningful commit message.
Then, go to your repo on GitHub and confirm that your changes are visible in your Rmd **and** md files.
If anything is missing, commit and push again.

## Packages

We'll use the **tidyverse** package for much of the data wrangling and visualisation and the data lives in the **dsbox** package.

You will need to install the packages and to install dsbox copy the following code into the console: 

```
install.packages("devtools")
devtools::install_github("tidyverse/dsbox")
```

You can load them by running the following in your Console:

```{r load-packages, message = FALSE, eval = TRUE}
library(tidyverse)
library(dsbox)
library(tidymodels)
library(flextable)
```

## Data

The data can be found in the **dsbox** package, and it's called `gss16`.
Since the dataset is distributed with the package, we don't need to load it separately; it becomes available to us when we load the package.
You can find out more about the dataset by inspecting its documentation, which you can access by running `?gss16` in the Console or using the Help menu in RStudio to search for `gss16`.
You can also find this information [here](https://rstudio-education.github.io/dsbox/reference/gss16.html).

# Exercises

## Part 1: Harassment at work

In 2016, the GSS added a new question on harassment at work.
The question is phrased as the following.

> *Over the past five years, have you been harassed by your superiors or co-workers at your job, for example, have you experienced any bullying, physical or psychological abuse?*

Answers to this question are stored in the `harass5` variable in our dataset.

1.  What are the possible responses to this question and how many respondents chose each of these answers?

```{r}

gss16 %>%
  count(harass5)

```

***The possible responses are `Yes`, `No`, and `Does not apply`. 96 people responded `Does not apply`, 1136 people responded `No`, and 237 people responded `Yes`. 1398 people left it blank (`NA`).***


2.  What percent of the respondents for whom this question is applicable\
    (i.e. excluding `NA`s and `Does not apply`s) have been harassed by their superiors or co-workers at their job.

``` {r}
237/(1136+237)*100   #number of Yes respondents divided by the sum of No and Yes (total excluding NA and Does not apply) multiplied by 100 to convert to a percent
```
***17.3% of the respondants for whom this question is applicable responded `Yes` (have been harrassed by their superiors or coworkers).***

üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*

## Part 2: Time spent on email

The 2016 GSS also asked respondents how many hours and minutes they spend on email weekly.
The responses to these questions are recorded in the `emailhr` and `emailmin` variables.
For example, if the response is 2.5 hrs, this would be recorded as `emailhr = 2` and `emailmin = 30`.

3.  Create a new variable called `email` that combines these two variables to reports the number of minutes the respondents spend on email weekly.

``` {r}
gss16 <- gss16 %>%         #writes the new variable to the dataframe
 mutate(email = emailhr * 60 + emailmin) #creates a new variable that reports the total number of minutes spent on email (combines emailhr and emailmin into one variable)
```

4.  Visualize the distribution of this new variable.
    Find the mean and the median number of minutes respondents spend on email weekly.
    Is the mean or the median a better measure of the typical among of time Americans spend on email weekly?
    Why?


``` {r}

gss16 %>%
  ggplot(mapping = aes(x = email)) +  
  geom_histogram(binwidth =250) +   #creates histogram
  labs(title = "Weekly Time Spent on Email by Americans", x = "Minutes", y = "Counts")            #adds labels

```

```{r}

gss16 %>%
  filter(!is.na(email)) %>%   #removes na values since they will interfer with summary statistics
  summarise(median = median(email), mean = mean(email))

```

***In this case, the median (120 min) is a better measure of the typical amount of time spent by Americans on email since it is less affected by extreme scores than the mean (416.84 min). From the visualization, one can see that the data is heavily skewed to the high end. The mean is more heavily affected by these extreme scores than the median making it less representative of the typical amount of time.***

5.  Create another new variable, `snap_insta` that is coded as "Yes" if the respondent reported using any of Snapchat (`snapchat`) or Instagram (`instagrm`), and "No" if not.
    If the recorded value was `NA` for both of these questions, the value in your new variable should also be `NA`.

```{r}

gss16 <- gss16 %>%          #saves the variable
  mutate(snap_insta =       #creates a new variable
           if_else(snapchat == "Yes" | instagrm == "Yes", "Yes",     #if either snapchat or instagrm are "Yes" then snap_insta will be "Yes"
                   if_else(snapchat == "No" | instagrm == "No", "No", "" )))         # if either snapchat or instagrm are "No" (and no previous "Yes" for the other variable) then snap_insta will be "No", else N/A
```

6.  Calculate the percentage of Yes's for `snap_insta` among those who answered the question, i.e. excluding `NA`s.

``` {r}
snap_insta_count_table <- table(gss16$snap_insta) #creates a table of counts (NAs are automatically excluded)

snap_insta_prop <- prop.table(snap_insta_count_table)           #converts table to proportions

round(snap_insta_prop * 100, digits = 2)
```
***37.46% of the people who answered the question responded `Yes` to using either snapchat or instagrm.***

7.  What are the possible responses to the question *Last week were you working full time, part time, going to school, keeping house, or what?* and how many respondents chose each of these answers?
    Note that this information is stored in the `wrkstat` variable.

``` {r}
gss16 %>%
  count(wrkstat) %>%
  arrange(desc(n))
```
***The possible responses to the question were `Working fulltime` (1321	respondents), `Retired`	(574 respondents), `Working parttime` (345 respondents), `Keeping house` (284 respondents), `Unempl, laid off` (118	respondents), `Other` (89 respondents), `School` (76 respondents), and `Temp not working` (57 respondents). 3 respondents left the question blank (`NA`).***

8.  Fit a model predicting `email` (number of minutes per week spent on email) from `educ` (number of years of education), `wrkstat`, and `snap_insta`.
    Interpret the slopes for each of these variables.

``` {r}
#find out if the data is linear or not

#gss16 %>%
  #ggplot(aes(x = educ, y = email)) +
  #geom_point(alpha = 0.25) +
  #geom_smooth(method = "lm", se = FALSE, color = "#CC5500") +
  #xlab("Years of Education") +
  #ylab("Minutes per Week Spent on Email") +
  #ggtitle("Scatter Plot of Years of Education to Minutes Spent on Email per Week")

email_educ_fit <- linear_reg() %>%   #saves regression data
  set_engine("lm") %>%               #sets the engine to linear
  fit(email ~ educ + wrkstat + snap_insta, data = gss16) # predicts email from educ, wrkstat, and snap_insta

email_educ_fit %>% tidy() #%>% flextable() #creates a cleaner output, removed due to a messy output when printing to pdf

```

**Slope - educ:** *All else held constant, for each additional year of education, we would expect time spent on email to be higher by 29.63 min.*


**Slope - wrskstat:** 

*All else held constant, people with a wrkstat of other, on average, spend 33.06 min more on email than those with a wrkstat of keeping house.*

*All else held constant, people with a wrkstat of retired, on average, spend 68.23 min more on email than those with a wrkstat of keeping house.*

*All else held constant, people with a wrkstat of school (students), on average, spend 123.81 min less on email than those with a wrkstat of keeping house.*

*All else held constant, people with a wrkstat of "Temp not working", on average, spend 73.71 min less on email than those with a wrkstat of keeping house.*

*All else held constant, people with a wrkstat of "Unempl, laid off",  on average, spend 118.35 min more on email than those with a wrkstat of keeping house.*

*All else held constant, people with a wrkstat of working fulltime, on average, spend 366.4 min more on email than those with a wrkstat of keeping house.*

*All else held constant, people with a wrkstat of workign parttime, on average, spend 18.90 more min on email than those with a wrkstat of keeping house.*


**Slope - snap_insta:** *All else held constant, people who use snapchat and instagrm, on average, spend 149.96 min more on email than those who don't use either.*

9.  Create a predicted values vs. residuals plot for this model.
    Are there any issues with the model?
    If yes, describe them.
    
``` {r}

email_educ_fit_aug <- augment(email_educ_fit$fit)

ggplot(email_educ_fit_aug, mapping = aes(x = .fitted, y = .resid)) +
 geom_point(alpha = 0.5) +
 geom_hline(yintercept = 0, color = "gray", lty = "dashed") +
 labs(x = "Predicted email", y = "Residuals", title = "Scatterplot of the Residuals for the Email Prediction Model")
```

***Yes, the plot of the residuals indicates that the model has a problem. The model uses a linear relationship, however, the plot of the residuals indicates that the relationship is non-linear. If it was linear, the residuals would be randomly distributed around 0 with no distinguishable pattern. However, the plot shows a negative, or fan-shaped pattern. To correct for this, the natural log of the data may need to be used.***

üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards.*

## Part 3: Political views and science research

The 2016 GSS also asked respondents whether they think of themselves as liberal or conservative (`polviews`) and whether they think science research is necessary and should be supported by the federal government (`advfront`).

-   The question on science research is worded as follows:

> Even if it brings no immediate benefits, scientific research that advances the frontiers of knowledge is necessary and should be supported by the federal government.

And possible responses to this question are Strongly agree, Agree, Disagree, Strongly disagree, Don't know, No answer, Not applicable.

-   The question on political views is worded as follows:

> We hear a lot of talk these days about liberals and conservatives.
> I'm going to show you a seven-point scale on which the political views that people might hold are arranged from extremely liberal--point 1--to extremely conservative--point 7.
> Where would you place yourself on this scale?


**Note:** The levels of this variables are spelled inconsistently: "Extremely liberal" vs. "Extrmly conservative". Since this is the spelling that shows up in the data, you need to make sure this is how you spell the levels in your code.


And possible responses to this question are Extremely liberal, Liberal, Slightly liberal, Moderate, Slghtly conservative, Conservative, Extrmly conservative.
Responses that were originally Don't know, No answer and Not applicable are already mapped to `NA`s upon data import.

10. In a new variable, recode `advfront` such that Strongly Agree and Agree are mapped to `"Yes"`, and Disagree and Strongly disagree are mapped to `"No"`.
    The remaining levels can be left as is.
    Don't overwrite the existing `advfront`, instead pick a different, informative name for your new variable.
    
```{r}
#gss16 %>%
  #count(advfront)              #pulls up the responses for appropriate spelling

gss16 <- 
  gss16 %>%
  mutate(advfront_simplified = if_else(advfront == "Strongly agree" | advfront == "Agree", "Yes",    #creates a new variable where the value is "Yes" if advfront is "Strongly agree" or "Agree"
                                       if_else(advfront == "Strongly disagree" | advfront == "Disagree", "No", advfront))) %>%                         # Assigns "No" to the variable if advfront is "Strongly disagree" or "Disagree". Else, the value from advfront (NA or "Dont know") is preserved
  #count(advfront_simplified)   # checks that all answers are perserved
  mutate(advfront_simplified = factor(advfront_simplified, levels = c("No", "Dont know", "Yes"))) #%>%  #assigns the levels
  #count(advfront_simplified)   #checks the correct order

```

11. In a new variable, recode `polviews` such that Extremely liberal, Liberal, and Slightly liberal, are mapped to `"Liberal"`, and Slghtly conservative, Conservative, and Extrmly conservative disagree are mapped to `"Conservative"`.
    The remaining levels can be left as is.
    Make sure that the levels are in a reasonable order.
    Don't overwrite the existing `polviews`, instead pick a different, informative name for your new variable.

```{r}
#gss16 %>%
  #count(polviews)              #pulls up the responses for appropriate spelling

#pol_levels <- c("Conservative", "Moderate", "Liberal")
gss16 <- 
  gss16 %>%
  mutate(polviews_simplified = fct_collapse(polviews,
          "Conservative" = c("Extrmly conservative", "Conservative", "Slghtly conservative"),  #combines all three answers into "Conservative"
          "Liberal" = c("Extremely liberal", "Liberal", "Slightly liberal"))) %>%                 #combines all three answers into "Liberal
    mutate(polviews_simplified = factor(polviews_simplified, levels = c("Conservative", "Moderate", "Liberal"))) #%>%
    #mutate(polviews_simplified = fct_relevel(pol_levels))
  #count(polviews_simplified)             # tests the correct order has been assigned
```
12. Create a visualization that displays the relationship between these two new variables and interpret it.

```{r}

gss16 %>%
  filter(!is.na(polviews_simplified), !is.na(advfront_simplified)) %>%
  ggplot(mapping = aes(x = polviews_simplified, fill = advfront_simplified)) +
  geom_bar(position = "fill") +
  labs(title = "Political Views and Support for Federally Supported Scientific Research without Immediate Benefit", x = "Political View", y = "Proportion of Support", fill = "Support for Research") +
  theme_minimal()
```

***From the visualization, we can see that support for federally supported research increases with political party (becoming more "liberal"). While across all categories, the majority answer is "Yes" to federally supported research, it is the greatest in Liberal, then Moderate, and lowest in Conservative. In addition to the increasing "Yes" positions, the proportion of the uncertain position "Dont know" also decreases while political party "increases". Finally, the proportion of "No" also decreases when political party "increases (however, Moderate and Liberal are almost identical in their proportions on this one).***

üß∂ ‚úÖ ‚¨ÜÔ∏è Knit, *commit, and push your changes to GitHub with an appropriate commit message. Make sure to commit and push all changed files so that your Git pane is cleared up afterwards and review the md document on GitHub to make sure you're happy with the final state of your work.*

